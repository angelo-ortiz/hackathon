{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "174e1e03",
   "metadata": {},
   "source": [
    "# Running MMS-ASR inference\n",
    "(Inspired from [this notebook](https://github.com/facebookresearch/fairseq/blob/main/examples/mms/asr/tutorial/MMS_ASR_Inference_Colab.ipynb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e00add",
   "metadata": {},
   "source": [
    "## 0. Preparation\n",
    "1. Clone the [repo](https://github.com/angelo-ortiz/hackathon) and install the environment. You can follow the instructions from the README file.\n",
    "2. Set the following variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dbe904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"TMPDIR\"] = '/Users/angelo/Documents/projects/hackathon/tmpdir'\n",
    "os.environ[\"PYTHONPATH\"] = \".\"\n",
    "os.environ[\"PREFIX\"] = \"INFER\"\n",
    "os.environ[\"HYDRA_FULL_ERROR\"] = \"1\"\n",
    "os.environ[\"USER\"] = \"myself\" # replace this with your login name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32afe868",
   "metadata": {},
   "source": [
    "## 1.  Tsimané audio transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3a1ae4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> preparing tmp manifest dir ...\n",
      ">>> loading model & running inference ...\n",
      "/Users/angelo/miniconda3/envs/hack/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "CompletedProcess(args='\\n        PYTHONPATH=. PREFIX=INFER HYDRA_FULL_ERROR=1 python examples/speech_recognition/new/infer.py -m --config-dir examples/mms/asr/config/ --config-name infer_common decoding.type=viterbi dataset.max_tokens=1440000 distributed_training.distributed_world_size=1 \"common_eval.path=\\'/Users/angelo/Downloads/mms1b_all.pt\\'\" task.data=/var/folders/g4/jddmfwsj68ldrs_7dwn_lq_40000gn/T/tmp28nxrd2j dataset.gen_subset=\"cas:dev\" common_eval.post_process=letter decoding.results_path=/var/folders/g4/jddmfwsj68ldrs_7dwn_lq_40000gn/T/tmp28nxrd2j \\n        ', returncode=0)\n",
      "===============\n",
      "Input: /Users/angelo/Documents/datasets/RedTeaming/extracted_audio/tsimane2017/tsimane2017_C01_20170706_16440000_16500000.wav\n",
      "Output: emu ti'dụ'jammujii ieeee o'caiei\n"
     ]
    }
   ],
   "source": [
    "!cd /Users/myself/Documents/fairseq && python examples/mms/asr/infer/mms_infer.py \\\n",
    "    --model \"/Users/myself/models_new/mms1b_all.pt\" \\\n",
    "    --lang \"cas\" \\\n",
    "    --audio \"/Users/myself/Documents/audio_samples/audio.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b414d4-85ef-41b7-9d27-931293089270",
   "metadata": {},
   "source": [
    "## 2. English audio transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8bdcb9f-438f-4f9e-87ec-7e45e7e89960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> preparing tmp manifest dir ...\n",
      ">>> loading model & running inference ...\n",
      "/Users/angelo/miniconda3/envs/hack/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/examples/speech_recognition/new/infer.py\", line 499, in <module>\n",
      "    cli_main()\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/examples/speech_recognition/new/infer.py\", line 495, in cli_main\n",
      "    hydra_main()  # pylint: disable=no-value-for-parameter\n",
      "  File \"/Users/angelo/miniconda3/envs/hack/lib/python3.10/site-packages/hydra/main.py\", line 32, in decorated_main\n",
      "    _run_hydra(\n",
      "  File \"/Users/angelo/miniconda3/envs/hack/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 354, in _run_hydra\n",
      "    run_and_report(\n",
      "  File \"/Users/angelo/miniconda3/envs/hack/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 201, in run_and_report\n",
      "    raise ex\n",
      "  File \"/Users/angelo/miniconda3/envs/hack/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 198, in run_and_report\n",
      "    return func()\n",
      "  File \"/Users/angelo/miniconda3/envs/hack/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 355, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/Users/angelo/miniconda3/envs/hack/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 136, in multirun\n",
      "    return sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/Users/angelo/miniconda3/envs/hack/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 154, in sweep\n",
      "    results = self.launcher.launch(batch, initial_job_idx=initial_job_idx)\n",
      "  File \"/Users/angelo/miniconda3/envs/hack/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_launcher.py\", line 76, in launch\n",
      "    ret = run_job(\n",
      "  File \"/Users/angelo/miniconda3/envs/hack/lib/python3.10/site-packages/hydra/core/utils.py\", line 129, in run_job\n",
      "    ret.return_value = task_function(task_cfg)\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/examples/speech_recognition/new/infer.py\", line 460, in hydra_main\n",
      "    distributed_utils.call_main(cfg, main)\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/fairseq/distributed/utils.py\", line 404, in call_main\n",
      "    main(cfg, **kwargs)\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/examples/speech_recognition/new/infer.py\", line 407, in main\n",
      "    with InferenceProcessor(cfg) as processor:\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/examples/speech_recognition/new/infer.py\", line 148, in __init__\n",
      "    self.progress_bar = self.build_progress_bar()\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/examples/speech_recognition/new/infer.py\", line 264, in build_progress_bar\n",
      "    iterator=self.get_dataset_itr(),\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/examples/speech_recognition/new/infer.py\", line 242, in get_dataset_itr\n",
      "    return self.task.get_batch_iterator(\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/fairseq/data/iterators.py\", line 420, in next_epoch_itr\n",
      "    self._cur_epoch_itr = self._get_iterator_for_epoch(\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/fairseq/data/iterators.py\", line 488, in _get_iterator_for_epoch\n",
      "    self.epoch_batch_sampler = FrozenBatchSampler(\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/fairseq/data/iterators.py\", line 248, in __init__\n",
      "    self.make_batches_for_epoch(epoch, initial_offset)\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/fairseq/data/iterators.py\", line 251, in make_batches_for_epoch\n",
      "    self.batches = self.ordered_batches(\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/fairseq/data/iterators.py\", line 566, in ordered_batches\n",
      "    batches = self.frozen_batches\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/fairseq/data/iterators.py\", line 358, in frozen_batches\n",
      "    self._frozen_batches = tuple(self.batch_sampler(self.dataset, self.epoch))\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/fairseq/tasks/fairseq_task.py\", line 300, in make_batches\n",
      "    batches = dataset.batch_by_size(\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/fairseq/data/base_wrapper_dataset.py\", line 61, in batch_by_size\n",
      "    return self.dataset.batch_by_size(\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/fairseq/data/fairseq_dataset.py\", line 145, in batch_by_size\n",
      "    return data_utils.batch_by_size(\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/fairseq/data/data_utils.py\", line 341, in batch_by_size\n",
      "    b = batch_by_size_fn(\n",
      "  File \"fairseq/data/data_utils_fast.pyx\", line 108, in fairseq.data.data_utils_fast.batch_by_size_fn\n",
      "    cpdef list batch_by_size_fn(\n",
      "  File \"fairseq/data/data_utils_fast.pyx\", line 123, in fairseq.data.data_utils_fast.batch_by_size_fn\n",
      "    return batch_by_size_vec(indices, num_tokens_vec, max_tokens,\n",
      "  File \"fairseq/data/data_utils_fast.pyx\", line 30, in fairseq.data.data_utils_fast.batch_by_size_vec\n",
      "    assert max_tokens <= 0 or np.max(num_tokens_vec) <= max_tokens, (\n",
      "AssertionError: Sentences lengths should not exceed max_tokens=1440000\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/examples/mms/asr/infer/mms_infer.py\", line 64, in <module>\n",
      "    process(args)\n",
      "  File \"/Users/angelo/Documents/projects/repos/fairseq/examples/mms/asr/infer/mms_infer.py\", line 52, in process\n",
      "    out = subprocess.run(cmd, check=True, shell=True, stdout=subprocess.DEVNULL,)\n",
      "  File \"/Users/angelo/miniconda3/envs/hack/lib/python3.10/subprocess.py\", line 526, in run\n",
      "    raise CalledProcessError(retcode, process.args,\n",
      "subprocess.CalledProcessError: Command '\n",
      "        PYTHONPATH=. PREFIX=INFER HYDRA_FULL_ERROR=1 python examples/speech_recognition/new/infer.py -m --config-dir examples/mms/asr/config/ --config-name infer_common decoding.type=viterbi dataset.max_tokens=1440000 distributed_training.distributed_world_size=1 \"common_eval.path='/Users/angelo/Downloads/mms1b_all.pt'\" task.data=/var/folders/g4/jddmfwsj68ldrs_7dwn_lq_40000gn/T/tmpomp__z0d dataset.gen_subset=\"fra:dev\" common_eval.post_process=letter decoding.results_path=/var/folders/g4/jddmfwsj68ldrs_7dwn_lq_40000gn/T/tmpomp__z0d \n",
      "        ' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!cd /Users/myself/Documents/fairseq && python examples/mms/asr/infer/mms_infer.py \\\n",
    "    --model \"/Users/myself/models_new/mms1b_all.pt\" \\\n",
    "    --lang \"eng\" \\\n",
    "    --audio \"/Users/myself/Documents/audio_samples/audio.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a03d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
